{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation Maximization Clustering\n",
    "\n",
    "\"The K-means approach is an example of a hard assignment clustering, where each point can belong to only one cluster. Expectation-Maximization algorithm is a way to generalize the approach to consider the soft assignment of points to clusters so that each point has a probability of belonging to each cluster.\"\n",
    "\n",
    "\"Maximum likelihood estimation is an approach to density estimation for a dataset by searching across probability distributions and their parameters.\n",
    "\n",
    "It is a general and effective approach that underlies many machine learning algorithms, although it requires that the training dataset is complete, e.g. all relevant interacting random variables are present. Maximum likelihood becomes intractable if there are variables that interact with those in the dataset but were hidden or not observed, so-called latent variables.\n",
    "\n",
    "The expectation-maximization algorithm is an approach for performing maximum likelihood estimation in the presence of latent variables. It does this by first estimating the values for the latent variables, then optimizing the model, then repeating these two steps until convergence. It is an effective and general approach and is most commonly used for density estimation with missing data, such as clustering algorithms like the Gaussian Mixture Model.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Failure Prediction Dataset - Standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ds_functions as ds\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data: pd.DataFrame = pd.read_csv('../../datasets/hf_scaled/HF_standardized.csv')\n",
    "data.pop('DEATH_EVENT') #Remove target variable\n",
    "\n",
    "N_CLUSTERS = [2, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 30]\n",
    "rows, cols = (11,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mse: list = []\n",
    "sc: list = []\n",
    "db: list = []\n",
    "    \n",
    "for n in range(len(N_CLUSTERS)):\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(cols*5, rows*5), squeeze=False)\n",
    "    i, j = 0, 0\n",
    "    \n",
    "    k = N_CLUSTERS[n]\n",
    "    estimator = GaussianMixture(n_components=k)\n",
    "    estimator.fit(data)\n",
    "    labels = estimator.predict(data)\n",
    "    \n",
    "    mse.append(ds.compute_mse(data.values, labels, estimator.means_))\n",
    "    sc.append(silhouette_score(data, labels))\n",
    "    db.append(davies_bouldin_score(data, labels))\n",
    "    \n",
    "    print(\"K - \" + str(n))\n",
    "    \n",
    "    for f1 in range (len(data.columns)):\n",
    "        for f2 in range(f1+1, len(data.columns)): \n",
    "            ds.plot_clusters(data, f2, f1, labels.astype(float), estimator.means_, k,\n",
    "                     f'EM k={k}', ax=axs[i,j])\n",
    "            \n",
    "            i, j = (i + 1, 0) if (j+1) % cols == 0 else (i, j + 1)    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,3))\n",
    "ds.plot_line(N_CLUSTERS, mse, title='EM MSE', xlabel='k', ylabel='MSE')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(9, 3), squeeze=False)\n",
    "ds.plot_line(N_CLUSTERS, sc, title='EM SC', xlabel='k', ylabel='SC', ax=ax[0, 0], percentage=True)\n",
    "ds.plot_line(N_CLUSTERS, db, title='EM DB', xlabel='k', ylabel='DB', ax=ax[0, 1], percentage=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\n",
    "Gaussian distributions are continuous distributions.\n",
    "\n",
    "There is no meaningful way to apply this famous \"bell shaped curve\" onto categorical data - binary encoding clearly does not make sense either. You have to find something else to use instead of Gaussians...\n",
    "\n",
    "So instead of hacking to make your data fake Gaussian, you should rather make the algorithm match your data and problem.\n",
    "\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means No Binary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data: pd.DataFrame = pd.read_csv('../../datasets/hf_scaled/HF_standardized.csv')\n",
    "data.pop('DEATH_EVENT') #Remove target variable\n",
    "numeric_vars = data.select_dtypes(include='number').columns\n",
    "\n",
    "numeric_data = data\n",
    "binary_data = data\n",
    "\n",
    "for n in range(len(numeric_vars)):\n",
    "    num_unique = len(list(set(data[numeric_vars[n]].values)))\n",
    "    if num_unique == 2:\n",
    "        numeric_data = numeric_data.drop(columns=[data.columns[n]], axis=1) #Remove binary columns\n",
    "\n",
    "    else:\n",
    "        binary_data = binary_data.drop(columns=[data.columns[n]], axis=1) #Remove non-binary columns\n",
    "\n",
    "print(numeric_data.head())\n",
    "data = numeric_data\n",
    "\n",
    "N_CLUSTERS = [2, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 30]\n",
    "rows, cols = (6,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mse: list = []\n",
    "sc: list = []\n",
    "db: list = []\n",
    "    \n",
    "for n in range(len(N_CLUSTERS)):\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(cols*5, rows*5), squeeze=False)\n",
    "    i, j = 0, 0\n",
    "    \n",
    "    k = N_CLUSTERS[n]\n",
    "    estimator = GaussianMixture(n_components=k)\n",
    "    estimator.fit(data)\n",
    "    labels = estimator.predict(data)\n",
    "    \n",
    "    mse.append(ds.compute_mse(data.values, labels, estimator.means_))\n",
    "    sc.append(silhouette_score(data, labels))\n",
    "    db.append(davies_bouldin_score(data, labels))\n",
    "    \n",
    "    print(\"K - \" + str(n))\n",
    "    \n",
    "    for f1 in range (len(data.columns)):\n",
    "        for f2 in range(f1+1, len(data.columns)): \n",
    "            ds.plot_clusters(data, f2, f1, labels.astype(float), estimator.means_, k,\n",
    "                     f'EM k={k}', ax=axs[i,j])\n",
    "            \n",
    "            i, j = (i + 1, 0) if (j+1) % cols == 0 else (i, j + 1)    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,3))\n",
    "ds.plot_line(N_CLUSTERS, mse, title='EM MSE', xlabel='k', ylabel='MSE')\n",
    "plt.show()\n",
    "\n",
    "print(db)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(9, 3), squeeze=False)\n",
    "ds.plot_line(N_CLUSTERS, sc, title='EM SC', xlabel='k', ylabel='SC', ax=ax[0, 0], percentage=True)\n",
    "ds.plot_line(N_CLUSTERS, db, title='EM DB', xlabel='k', ylabel='DB', ax=ax[0, 1], percentage=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Failure Prediction Dataset - Standardized + ANOVA + FG + Outlier + Balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ds_functions as ds\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data: pd.DataFrame = pd.read_csv('../../datasets/TO_TEST/HF/HF_S_FAnova_extra_outlierTrim_IQS_B.csv')\n",
    "data.pop('DEATH_EVENT') #Remove target variable\n",
    "\n",
    "N_CLUSTERS = [2, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 30]\n",
    "rows, cols = (10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mse: list = []\n",
    "sc: list = []\n",
    "db: list = []\n",
    "    \n",
    "for n in range(len(N_CLUSTERS)):\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(cols*5, rows*5), squeeze=False)\n",
    "    i, j = 0, 0\n",
    "    \n",
    "    k = N_CLUSTERS[n]\n",
    "    estimator = GaussianMixture(n_components=k)\n",
    "    estimator.fit(data)\n",
    "    labels = estimator.predict(data)\n",
    "    \n",
    "    mse.append(ds.compute_mse(data.values, labels, estimator.means_))\n",
    "    sc.append(silhouette_score(data, labels))\n",
    "    db.append(davies_bouldin_score(data, labels))\n",
    "    \n",
    "    print(\"K - \" + str(n))\n",
    "    \n",
    "    for f1 in range (len(data.columns)):\n",
    "        for f2 in range(f1+1, len(data.columns)): \n",
    "            ds.plot_clusters(data, f2, f1, labels.astype(float), estimator.means_, k,\n",
    "                     f'EM k={k}', ax=axs[i,j])\n",
    "            \n",
    "            i, j = (i + 1, 0) if (j+1) % cols == 0 else (i, j + 1)    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,3))\n",
    "ds.plot_line(N_CLUSTERS, mse, title='EM MSE', xlabel='k', ylabel='MSE')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(9, 3), squeeze=False)\n",
    "ds.plot_line(N_CLUSTERS, sc, title='EM SC', xlabel='k', ylabel='SC', ax=ax[0, 0], percentage=True)\n",
    "ds.plot_line(N_CLUSTERS, db, title='EM DB', xlabel='k', ylabel='DB', ax=ax[0, 1], percentage=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Yes, it is unlikely that binary data can be clustered satisfactorily. To see why, consider what happens as the K-Means algorithm processes cases.\n",
    "\n",
    "For binary data, the Euclidean distance measure used by K-Means reduces to counting the number of variables on which two cases disagree. After the initial centers are chosen (which depends on the order of the cases), the centers are still binary data. For the first iteration, as the cases are compared to cluster means, they will always be at some integer distance from each of the centers. There will often be ties, and the case will be assigned to a cluster in an arbitrary manner. Using Euclidean distance (the only measure available to K-Means), it is impossible to overcome the symmetry and break the ties in any meaningful way.\n",
    "\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means No Binary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data: pd.DataFrame = pd.read_csv('../../datasets/TO_TEST/HF/HF_S_FAnova_extra_outlierTrim_IQS_B.csv')\n",
    "data.pop('DEATH_EVENT') #Remove target variable\n",
    "numeric_vars = data.select_dtypes(include='number').columns\n",
    "\n",
    "numeric_data = data\n",
    "binary_data = data\n",
    "\n",
    "for n in range(len(numeric_vars)):\n",
    "    num_unique = len(list(set(data[numeric_vars[n]].values)))\n",
    "    if num_unique == 2 or num_unique == 1:\n",
    "        numeric_data = numeric_data.drop(columns=[data.columns[n]], axis=1) #Remove binary columns\n",
    "    else:\n",
    "        binary_data = binary_data.drop(columns=[data.columns[n]], axis=1) #Remove non-binary columns\n",
    "\n",
    "print(numeric_data.head())\n",
    "data = numeric_data\n",
    "\n",
    "N_CLUSTERS = [2, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 30]\n",
    "rows, cols = (6,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mse: list = []\n",
    "sc: list = []\n",
    "db: list = []\n",
    "    \n",
    "for n in range(len(N_CLUSTERS)):\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(cols*5, rows*5), squeeze=False)\n",
    "    i, j = 0, 0\n",
    "    \n",
    "    k = N_CLUSTERS[n]\n",
    "    estimator = GaussianMixture(n_components=k)\n",
    "    estimator.fit(data)\n",
    "    labels = estimator.predict(data)\n",
    "    \n",
    "    mse.append(ds.compute_mse(data.values, labels, estimator.means_))\n",
    "    sc.append(silhouette_score(data, labels))\n",
    "    db.append(davies_bouldin_score(data, labels))\n",
    "    \n",
    "    print(\"K - \" + str(n))\n",
    "    \n",
    "    for f1 in range (len(data.columns)):\n",
    "        for f2 in range(f1+1, len(data.columns)): \n",
    "            ds.plot_clusters(data, f2, f1, labels.astype(float), estimator.means_, k,\n",
    "                     f'EM k={k}', ax=axs[i,j])\n",
    "            \n",
    "            i, j = (i + 1, 0) if (j+1) % cols == 0 else (i, j + 1)    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,3))\n",
    "ds.plot_line(N_CLUSTERS, mse, title='EM MSE', xlabel='k', ylabel='MSE')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(9, 3), squeeze=False)\n",
    "ds.plot_line(N_CLUSTERS, sc, title='EM SC', xlabel='k', ylabel='SC', ax=ax[0, 0], percentage=True)\n",
    "ds.plot_line(N_CLUSTERS, db, title='EM DB', xlabel='k', ylabel='DB', ax=ax[0, 1], percentage=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Failure Prediction Dataset - Standardized + Importance + FG + Outlier + Balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ds_functions as ds\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data: pd.DataFrame = pd.read_csv('../../datasets/TO_TEST/HF/HR_S_FImp_extra_outlierTrim_IQS_B.csv')\n",
    "data.pop('DEATH_EVENT') #Remove target variable\n",
    "\n",
    "N_CLUSTERS = [2, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 30]\n",
    "rows, cols = (5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mse: list = []\n",
    "sc: list = []\n",
    "db: list = []\n",
    "    \n",
    "for n in range(len(N_CLUSTERS)):\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(cols*5, rows*5), squeeze=False)\n",
    "    i, j = 0, 0\n",
    "    \n",
    "    k = N_CLUSTERS[n]\n",
    "    estimator = GaussianMixture(n_components=k)\n",
    "    estimator.fit(data)\n",
    "    labels = estimator.predict(data)\n",
    "    \n",
    "    mse.append(ds.compute_mse(data.values, labels, estimator.means_))\n",
    "    sc.append(silhouette_score(data, labels))\n",
    "    db.append(davies_bouldin_score(data, labels))\n",
    "    \n",
    "    print(\"K - \" + str(n))\n",
    "    \n",
    "    for f1 in range (len(data.columns)):\n",
    "        for f2 in range(f1+1, len(data.columns)): \n",
    "            ds.plot_clusters(data, f2, f1, labels.astype(float), estimator.means_, k,\n",
    "                     f'EM k={k}', ax=axs[i,j])\n",
    "            \n",
    "            i, j = (i + 1, 0) if (j+1) % cols == 0 else (i, j + 1)    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,3))\n",
    "ds.plot_line(N_CLUSTERS, mse, title='EM MSE', xlabel='k', ylabel='MSE')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(9, 3), squeeze=False)\n",
    "ds.plot_line(N_CLUSTERS, sc, title='EM SC', xlabel='k', ylabel='SC', ax=ax[0, 0], percentage=True)\n",
    "ds.plot_line(N_CLUSTERS, db, title='EM DB', xlabel='k', ylabel='DB', ax=ax[0, 1], percentage=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Yes, it is unlikely that binary data can be clustered satisfactorily. To see why, consider what happens as the K-Means algorithm processes cases.\n",
    "\n",
    "For binary data, the Euclidean distance measure used by K-Means reduces to counting the number of variables on which two cases disagree. After the initial centers are chosen (which depends on the order of the cases), the centers are still binary data. For the first iteration, as the cases are compared to cluster means, they will always be at some integer distance from each of the centers. There will often be ties, and the case will be assigned to a cluster in an arbitrary manner. Using Euclidean distance (the only measure available to K-Means), it is impossible to overcome the symmetry and break the ties in any meaningful way.\n",
    "\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means No Binary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data: pd.DataFrame = pd.read_csv('../../datasets/TO_TEST/HF/HR_S_FImp_extra_outlierTrim_IQS_B.csv')\n",
    "data.pop('DEATH_EVENT') #Remove target variable\n",
    "numeric_vars = data.select_dtypes(include='number').columns\n",
    "\n",
    "numeric_data = data\n",
    "binary_data = data\n",
    "\n",
    "for n in range(len(numeric_vars)):\n",
    "    num_unique = len(list(set(data[numeric_vars[n]].values)))\n",
    "    if num_unique == 2 or num_unique == 1:\n",
    "        numeric_data = numeric_data.drop(columns=[data.columns[n]], axis=1) #Remove binary columns\n",
    "    else:\n",
    "        binary_data = binary_data.drop(columns=[data.columns[n]], axis=1) #Remove non-binary columns\n",
    "\n",
    "print(numeric_data.head())\n",
    "data = numeric_data\n",
    "\n",
    "N_CLUSTERS = [2, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 30]\n",
    "rows, cols = (6,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mse: list = []\n",
    "sc: list = []\n",
    "db: list = []\n",
    "    \n",
    "for n in range(len(N_CLUSTERS)):\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(cols*5, rows*5), squeeze=False)\n",
    "    i, j = 0, 0\n",
    "    \n",
    "    k = N_CLUSTERS[n]\n",
    "    estimator = GaussianMixture(n_components=k)\n",
    "    estimator.fit(data)\n",
    "    labels = estimator.predict(data)\n",
    "    \n",
    "    mse.append(ds.compute_mse(data.values, labels, estimator.means_))\n",
    "    sc.append(silhouette_score(data, labels))\n",
    "    db.append(davies_bouldin_score(data, labels))\n",
    "    \n",
    "    print(\"K - \" + str(n))\n",
    "    \n",
    "    for f1 in range (len(data.columns)):\n",
    "        for f2 in range(f1+1, len(data.columns)): \n",
    "            ds.plot_clusters(data, f2, f1, labels.astype(float), estimator.means_, k,\n",
    "                     f'EM k={k}', ax=axs[i,j])\n",
    "            \n",
    "            i, j = (i + 1, 0) if (j+1) % cols == 0 else (i, j + 1)    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,3))\n",
    "ds.plot_line(N_CLUSTERS, mse, title='EM MSE', xlabel='k', ylabel='MSE')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(9, 3), squeeze=False)\n",
    "ds.plot_line(N_CLUSTERS, sc, title='EM SC', xlabel='k', ylabel='SC', ax=ax[0, 0], percentage=True)\n",
    "ds.plot_line(N_CLUSTERS, db, title='EM DB', xlabel='k', ylabel='DB', ax=ax[0, 1], percentage=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Failure Prediction Dataset - Standardized + Mixed + Outlier + Balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ds_functions as ds\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data: pd.DataFrame = pd.read_csv('../../datasets/TO_TEST/HF/HR_S_FMixed_outlierTrim_IQS_B.csv')\n",
    "data.pop('DEATH_EVENT') #Remove target variable\n",
    "\n",
    "N_CLUSTERS = [2, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 30]\n",
    "rows, cols = (2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mse: list = []\n",
    "sc: list = []\n",
    "db: list = []\n",
    "    \n",
    "for n in range(len(N_CLUSTERS)):\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(cols*5, rows*5), squeeze=False)\n",
    "    i, j = 0, 0\n",
    "    \n",
    "    k = N_CLUSTERS[n]\n",
    "    estimator = GaussianMixture(n_components=k)\n",
    "    estimator.fit(data)\n",
    "    labels = estimator.predict(data)\n",
    "    \n",
    "    mse.append(ds.compute_mse(data.values, labels, estimator.means_))\n",
    "    sc.append(silhouette_score(data, labels))\n",
    "    db.append(davies_bouldin_score(data, labels))\n",
    "    \n",
    "    print(\"K - \" + str(n))\n",
    "    \n",
    "    for f1 in range (len(data.columns)):\n",
    "        for f2 in range(f1+1, len(data.columns)): \n",
    "            ds.plot_clusters(data, f2, f1, labels.astype(float), estimator.means_, k,\n",
    "                     f'EM k={k}', ax=axs[i,j])\n",
    "            \n",
    "            i, j = (i + 1, 0) if (j+1) % cols == 0 else (i, j + 1)    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,3))\n",
    "ds.plot_line(N_CLUSTERS, mse, title='EM MSE', xlabel='k', ylabel='MSE')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(9, 3), squeeze=False)\n",
    "ds.plot_line(N_CLUSTERS, sc, title='EM SC', xlabel='k', ylabel='SC', ax=ax[0, 0], percentage=True)\n",
    "ds.plot_line(N_CLUSTERS, db, title='EM DB', xlabel='k', ylabel='DB', ax=ax[0, 1], percentage=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Yes, it is unlikely that binary data can be clustered satisfactorily. To see why, consider what happens as the K-Means algorithm processes cases.\n",
    "\n",
    "For binary data, the Euclidean distance measure used by K-Means reduces to counting the number of variables on which two cases disagree. After the initial centers are chosen (which depends on the order of the cases), the centers are still binary data. For the first iteration, as the cases are compared to cluster means, they will always be at some integer distance from each of the centers. There will often be ties, and the case will be assigned to a cluster in an arbitrary manner. Using Euclidean distance (the only measure available to K-Means), it is impossible to overcome the symmetry and break the ties in any meaningful way.\n",
    "\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means No Binary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data: pd.DataFrame = pd.read_csv('../../datasets/TO_TEST/HF/HR_S_FMixed_outlierTrim_IQS_B.csv')\n",
    "data.pop('DEATH_EVENT') #Remove target variable\n",
    "numeric_vars = data.select_dtypes(include='number').columns\n",
    "\n",
    "numeric_data = data\n",
    "binary_data = data\n",
    "\n",
    "for n in range(len(numeric_vars)):\n",
    "    num_unique = len(list(set(data[numeric_vars[n]].values)))\n",
    "    if num_unique == 2 or num_unique == 1:\n",
    "        numeric_data = numeric_data.drop(columns=[data.columns[n]], axis=1) #Remove binary columns\n",
    "    else:\n",
    "        binary_data = binary_data.drop(columns=[data.columns[n]], axis=1) #Remove non-binary columns\n",
    "\n",
    "print(numeric_data.head())\n",
    "data = numeric_data\n",
    "\n",
    "N_CLUSTERS = [2, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 30]\n",
    "rows, cols = (3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mse: list = []\n",
    "sc: list = []\n",
    "db: list = []\n",
    "    \n",
    "for n in range(len(N_CLUSTERS)):\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(cols*5, rows*5), squeeze=False)\n",
    "    i, j = 0, 0\n",
    "    \n",
    "    k = N_CLUSTERS[n]\n",
    "    estimator = GaussianMixture(n_components=k)\n",
    "    estimator.fit(data)\n",
    "    labels = estimator.predict(data)\n",
    "    \n",
    "    mse.append(ds.compute_mse(data.values, labels, estimator.means_))\n",
    "    sc.append(silhouette_score(data, labels))\n",
    "    db.append(davies_bouldin_score(data, labels))\n",
    "    \n",
    "    print(\"K - \" + str(n))\n",
    "    \n",
    "    for f1 in range (len(data.columns)):\n",
    "        for f2 in range(f1+1, len(data.columns)): \n",
    "            ds.plot_clusters(data, f2, f1, labels.astype(float), estimator.means_, k,\n",
    "                     f'EM k={k}', ax=axs[i,j])\n",
    "            \n",
    "            i, j = (i + 1, 0) if (j+1) % cols == 0 else (i, j + 1)    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,3))\n",
    "ds.plot_line(N_CLUSTERS, mse, title='EM MSE', xlabel='k', ylabel='MSE')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(9, 3), squeeze=False)\n",
    "ds.plot_line(N_CLUSTERS, sc, title='EM SC', xlabel='k', ylabel='SC', ax=ax[0, 0], percentage=True)\n",
    "ds.plot_line(N_CLUSTERS, db, title='EM DB', xlabel='k', ylabel='DB', ax=ax[0, 1], percentage=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
